{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW3\n",
    "# Lakshya Tiwari\n",
    "# 1222259194"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PROBLEM 1\n",
    "# The Optimization problem can be formulated as $\\underset{A_{12},A_{21}}{min} \\sum_{i}(\\hat{p}_{i}-p^{obs}_{i})^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "\n",
    "import torch as t\n",
    "from torch.autograd import Variable\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Calculation Of Saturation Pressure\n",
    "\n",
    "p_sat14=10**(7.43155 - 1554.679/(20+240.337))\n",
    "p_satw=10**(8.071 - 1730.63/(20+233.426))\n",
    "\n",
    "p_g=[ 28.1 , 34.4 , 36.7 , 36.9 , 36.8 , 36.7 , 36.5 , 35.4 , 32.9 , 27.7 , 17.5 ]\n",
    "x_g=[ 0.0 , 0.1 , 0.2 , 0.3 , 0.4 , 0.5 , 0.6 , 0.7 , 0.8 , 0.9 , 1.0 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saturation Pressure of 1,4 dioxane is 28.824099527405245\n",
      "Saturation Pressure of water is 17.460784103526855\n"
     ]
    }
   ],
   "source": [
    "# Saturation Pressure\n",
    "\n",
    "print(\"Saturation Pressure of 1,4 dioxane is\", p_sat14)\n",
    "print(\"Saturation Pressure of water is\", p_satw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#Functions\n",
    "\n",
    "# Pressure\n",
    "def p(a,x1):\n",
    "    x2=1-x1\n",
    "    return x1 * t.exp(a[0]* ( (a[1]*x2)/(a[0]*x1 + a[1]*x2) )**2 ) * p_satw + x2 * t.exp(a[1]* ( (a[0]*x1)/(a[0]*x1 + a[1]*x2) )**2 ) * p_sat14\n",
    "\n",
    "# Total sum\n",
    "def TS(a):\n",
    "    t=0\n",
    "    for i in range(len(x_g)):\n",
    "        xi=x_g[i]\n",
    "        P=p(a,xi)\n",
    "        t += (P-p_g[i])**2\n",
    "    return t\n",
    "\n",
    "# Step\n",
    "def l(a):\n",
    "    s=0.1\n",
    "    while TS(a-s*a.grad) > TS(a)-s*(0)*np.matmul(a.grad, a.grad):\n",
    "        s=.25*s\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final value of a is [1.9594604 1.6896328]\n",
      "The value of objective function is 0.67127305\n"
     ]
    }
   ],
   "source": [
    "# Assuming initial values for A12 and A21 as 2 & 1.\n",
    "a = Variable(t.tensor([2.0, 1.0]), requires_grad=True)\n",
    "\n",
    "# Error\n",
    "e = 150\n",
    "\n",
    "# Gradient Descent\n",
    "while e > 0.15:\n",
    "    obj=TS(a)\n",
    "    obj.backward()\n",
    "    step=l(a)\n",
    "    e = t.linalg.norm(a.grad)\n",
    "    with t.no_grad():\n",
    "        a -= step * a.grad\n",
    "        a.grad.zero_()\n",
    "\n",
    "print('Final value of a is ' + str(a.data.numpy()))\n",
    "print('The value of objective function is ' + str(obj.data.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given P        Modelled P\n",
      "28.1        28.824098587036133\n",
      "34.4        34.64482498168945\n",
      "36.7        36.45182800292969\n",
      "36.9        36.86505126953125\n",
      "36.8        36.87146759033203\n",
      "36.7        36.747562408447266\n",
      "36.5        36.3885498046875\n",
      "35.4        35.38287353515625\n",
      "32.9        32.94468688964844\n",
      "27.7        27.723770141601562\n",
      "17.5        17.460784912109375\n"
     ]
    }
   ],
   "source": [
    "# Comparison between given data and modelled data\n",
    "print('Given P        Modelled P')\n",
    "for i in range(0,11):\n",
    "    print(str(p_g[i]) + '        ' + str(p(a.data,x_g[i]).item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The modelled pressures fit very well with the values given in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PROBLEM 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "\n",
    "import numpy as np\n",
    "import sklearn.gaussian_process as gp\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# EXPECTED IMPROVEMENT function.\n",
    "\n",
    "def expected_improvement(x, gaussian_process, evaluated_loss, greater_is_better=False, n_params=1):\n",
    "\n",
    "    x_to_predict = x.reshape(-1, n_params)\n",
    "\n",
    "    mu, sigma = gaussian_process.predict(x_to_predict, return_std=True)\n",
    "\n",
    "    if greater_is_better:\n",
    "        loss_optimum = np.max(evaluated_loss)\n",
    "    else:\n",
    "        loss_optimum = np.min(evaluated_loss)\n",
    "\n",
    "    scaling_factor = (-1) ** (not greater_is_better)\n",
    "\n",
    "    # In case sigma equals zero\n",
    "    with np.errstate(divide='ignore'):\n",
    "        Z = scaling_factor * (mu - loss_optimum) / sigma\n",
    "        expected_improvement = scaling_factor * (mu - loss_optimum) * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
    "        expected_improvement[sigma == 0.0] == 0.0\n",
    "\n",
    "    return -1 * expected_improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# HYPERPARAMETER function.\n",
    "\n",
    "def sample_next_hyperparameter(acquisition_func, gaussian_process, evaluated_loss, greater_is_better=False,\n",
    "                               bounds=(0, 10), n_restarts=25):\n",
    "    best_x = None\n",
    "    best_acquisition_value = 1\n",
    "    n_params = bounds.shape[0]\n",
    "\n",
    "    for starting_point in np.random.uniform(bounds[:, 0], bounds[:, 1], size=(n_restarts, n_params)):\n",
    "\n",
    "        res = minimize(fun=acquisition_func,\n",
    "                       x0=starting_point.reshape(1, -1),\n",
    "                       bounds=bounds,\n",
    "                       method='L-BFGS-B',\n",
    "                       args=(gaussian_process, evaluated_loss, greater_is_better, n_params))\n",
    "\n",
    "        if res.fun < best_acquisition_value:\n",
    "            best_acquisition_value = res.fun\n",
    "            best_x = res.x\n",
    "\n",
    "    return best_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# BAYESIAN OPTIMIZATION function.\n",
    "\n",
    "def bayesian_optimisation(n_iters, sample_loss, bounds, x0=None, n_pre_samples=5,\n",
    "                          gp_params=None, random_search=False, alpha=1e-5, epsilon=1e-7):\n",
    "\n",
    "    x_list = []\n",
    "    y_list = []\n",
    "\n",
    "    n_params = bounds.shape[0]\n",
    "\n",
    "    if x0 is None:\n",
    "        for params in np.random.uniform(bounds[:, 0], bounds[:, 1], (n_pre_samples, bounds.shape[0])):\n",
    "            x_list.append(params)\n",
    "            y_list.append(sample_loss(params))\n",
    "    else:\n",
    "        for params in x0:\n",
    "            x_list.append(params)\n",
    "            y_list.append(sample_loss(params))\n",
    "\n",
    "    xp = np.array(x_list)\n",
    "    yp = np.array(y_list)\n",
    "\n",
    "    # Create the GP\n",
    "    if gp_params is not None:\n",
    "        model = gp.GaussianProcessRegressor(**gp_params)\n",
    "    else:\n",
    "        kernel = gp.kernels.Matern()\n",
    "        model = gp.GaussianProcessRegressor(kernel=kernel,\n",
    "                                            alpha=alpha,\n",
    "                                            n_restarts_optimizer=10,\n",
    "                                            normalize_y=True)\n",
    "\n",
    "    for n in range(n_iters):\n",
    "\n",
    "        model.fit(xp, yp)\n",
    "\n",
    "        # Sample next hyperparameter\n",
    "        if random_search:\n",
    "            x_random = np.random.uniform(bounds[:, 0], bounds[:, 1], size=(random_search, n_params))\n",
    "            ei = -1 * expected_improvement(x_random, model, yp, greater_is_better=True, n_params=n_params)\n",
    "            next_sample = x_random[np.argmax(ei), :]\n",
    "        else:\n",
    "            next_sample = sample_next_hyperparameter(expected_improvement, model, yp, greater_is_better=True, bounds=bounds, n_restarts=100)\n",
    "\n",
    "        # Duplicates will break the GP. In case of a duplicate, we will randomly sample a next query point.\n",
    "        if np.any(np.abs(next_sample - xp) <= epsilon):\n",
    "            next_sample = np.random.uniform(bounds[:, 0], bounds[:, 1], bounds.shape[0])\n",
    "\n",
    "        # Sample loss for new set of parameters\n",
    "        cv_score = sample_loss(next_sample)\n",
    "\n",
    "        # Update lists\n",
    "        x_list.append(next_sample)\n",
    "        y_list.append(cv_score)\n",
    "\n",
    "        # Update xp and yp\n",
    "        xp = np.array(x_list)\n",
    "        yp = np.array(y_list)\n",
    "\n",
    "    return xp, yp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Setup\n",
    "\n",
    "# Bounds\n",
    "b = np.array([[-3, 3],[-2,2]])\n",
    "# Function\n",
    "def fun(x):\n",
    "    x1=x[0]\n",
    "    x2=x[1]\n",
    "    return -1*((4 - 2.1*x1**2 + (x1**4)/3)*x1**2 + x1*x2 + (-4 + 4*(x2**2))*x2**2)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Bayesian Optimisation\n",
    "z1, z2 = bayesian_optimisation(100, fun, b, n_pre_samples=5, random_search=100000, alpha=1e-5, epsilon=1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of X1 and X2 is \t [-0.09323019  0.85790966]\n",
      "Value of minimized function is \t 0.8225730773274305\n"
     ]
    }
   ],
   "source": [
    "# Solution\n",
    "print('Value of X1 and X2 is \\t', z1[100])\n",
    "print('Value of minimized function is \\t', z2[100])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
